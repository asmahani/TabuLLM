import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sentence_transformers import SentenceTransformer
from gensim.utils import simple_preprocess
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel
import vertexai

class TextColumnTransformer(BaseEstimator, TransformerMixin):
    """
    A transformer for converting one or more text columns to a numeric matrix using various embedding models.

    This class supports the following text embedding models:
    - OpenAI's large language models (LLM) for embedding
    - Sentence-Transformer (ST) embedding LLMs
    - Doc2Vec (via gensim package)
    - Google Vertex AI's embedding LLMs

    Parameters
    ----------
    type : str, default='doc2vec'
        The type of embedding model to use. Must be one of 'openai', 'st', 'doc2vec', or 'google'.
    openai_client : object, optional
        The OpenAI client object for accessing OpenAI's embedding models.
    google_project_id : str, optional
        The Google Cloud project ID for accessing Google Vertex AI.
    google_location : str, optional
        The location of the Google Vertex AI resources.
    embedding_model_openai : str, default='text-embedding-3-large'
        The specific OpenAI embedding model to use.
    embedding_model_st : str, default='neuml/pubmedbert-base-embeddings-matryoshka'
        The specific Sentence Transformer model to use.
    embedding_model_doc2vec : str, default='PV-DM'
        The specific Doc2Vec model to use. Must be one of 'PV-DM' or 'PV-DBOW'.
    embedding_model_google : str, default='text-embedding-004'
        The specific Google Vertex AI embedding model to use.
    doc2vec_epochs : int, default=40
        The number of training epochs for the Doc2Vec model.
    doc2vec_vector_size : int, default=10
        The size of the vectors generated by the Doc2Vec model.
    google_task : str, default='SEMANTIC_SIMILARITY'
        The task type for Google Vertex AI.
    google_batch_size : int, default=250
        The batch size for Google Vertex AI requests.
    colsep : str, default=' || '
        The column separator for the input text.
    return_cols_prefix : str, default='X_'
        The prefix for the returned columns.

    Raises
    ------
    ValueError
        If an invalid embedding type or Doc2Vec model is specified.

    Attributes
    ----------
    type : str
        The type of embedding model being used.
    openai_client : object
        The OpenAI client object.
    google_project_id : str
        The Google Cloud project ID.
    google_location : str
        The location of the Google Vertex AI resources.
    embedding_model_openai : str
        The specific OpenAI embedding model.
    embedding_model_st : str
        The specific Sentence Transformer model.
    embedding_model_doc2vec : str
        The specific Doc2Vec model.
    embedding_model_google : str
        The specific Google Vertex AI embedding model.
    doc2vec_epochs : int
        The number of training epochs for the Doc2Vec model.
    doc2vec_vector_size : int
        The size of the vectors generated by the Doc2Vec model.
    google_task : str
        The task type for Google Vertex AI.
    google_batch_size : int
        The batch size for Google Vertex AI requests.
    colsep : str
        The column separator for the input text.
    return_cols_prefix : str
        The prefix for the returned columns.
    """
    
    def __init__(
        self
        , type = 'doc2vec'
        , openai_client = None
        , google_project_id = None
        , google_location = None
        , embedding_model_openai = 'text-embedding-3-large'
        , embedding_model_st = 'neuml/pubmedbert-base-embeddings-matryoshka'
        , embedding_model_doc2vec = 'PV-DM'
        , embedding_model_google = 'text-embedding-004'
        , doc2vec_epochs = 40
        , doc2vec_vector_size = 10
        , google_task = 'SEMANTIC_SIMILARITY'
        , google_batch_size = 250
        , colsep = ' || '
        , return_cols_prefix = 'X_'
    ):
        if not (type in ('openai', 'st', 'doc2vec', 'google')):
            raise ValueError('Invalid embedding type')
        if not (embedding_model_doc2vec in ('PV-DM', 'PV-DBOW')):
            raise ValueError('Doc2Vec model must be one of "PV-DM" or "PV-DBOW"')
        
        self.type = type
        self.openai_client = openai_client
        self.google_project_id = google_project_id
        self.google_location = google_location
        self.embedding_model_openai = embedding_model_openai
        self.embedding_model_st = embedding_model_st
        self.embedding_model_doc2vec = embedding_model_doc2vec
        self.embedding_model_google = embedding_model_google
        self.colsep = colsep
        self.return_cols_prefix = return_cols_prefix
        self.doc2vec_epochs = doc2vec_epochs
        self.doc2vec_vector_size = doc2vec_vector_size
        self.google_task = google_task
        self.google_batch_size = google_batch_size
        
        pass
    
    def _fit_doc2vec(self, X, y = None):
        if not (X.dtypes == 'object').all():
            raise TypeError('All columns of X must be of string (object) type')
        
        Xstr = X.fillna('').astype(str).apply(
            lambda row: self.colsep.join([f'{col}: {row[col]}' for col in X.columns])
            , axis=1
        ).tolist()
        
        corpus = [TaggedDocument(words = simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(Xstr)]
        alg = 1 if self.embedding_model_doc2vec == 'PV-DM' else 0
        model = Doc2Vec(corpus, vector_size = self.doc2vec_vector_size, window=2, min_count=1, epochs = self.doc2vec_epochs, dm = alg)
        self.doc2vec_model = model
        return self
    
    def fit(self, X, y = None):
        """
        Fit the transformer on the data.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to fit.
        y : array-like of shape (n_samples,), optional
            The target values (ignored).

        Returns
        -------
        self : object
            Returns the instance itself.
        """
        if self.type == 'doc2vec':
            return self._fit_doc2vec(X, y)
        else:
            return self

    def fit_transform(self, X, y = None):
        """
        Fit the transformer on the data and then transform it.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to fit and transform.
        y : array-like of shape (n_samples,), optional
            The target values (ignored).

        Returns
        -------
        embeddings : numpy.ndarray of shape (n_samples, embedding_dim)
            The transformed embeddings.
        """
        if self.type == 'doc2vec':
            self._fit_doc2vec(X, y)
        return self.transform(X)
    
    def transform(self, X):
        """
        Transform the data into embeddings.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to transform.

        Returns
        -------
        embeddings : numpy.ndarray of shape (n_samples, embedding_dim)
            The transformed embeddings.
        """
        
        if not (X.dtypes == 'object').all():
            raise TypeError('All columns of X must be of string (object) type')
        
        Xstr = X.fillna('').astype(str).apply(
            lambda row: self.colsep.join([f'{col}: {row[col]}' for col in X.columns])
            , axis=1
        ).tolist()
        
        if self.type == 'openai':
            arr = self._transform_openai(Xstr)
        elif self.type == 'st':
            arr = self._transform_st(Xstr)
        elif self.type == 'doc2vec':
            arr = self._transform_doc2vec(Xstr)
        elif self.type == 'google':
            arr = self._transform_google(Xstr)
        else:
            raise ValueError('Invalid embedding type')
        return pd.DataFrame(arr, columns = [self.return_cols_prefix + str(i) for i in range(arr.shape[1])])

    def _transform_google(self, X):
        vertexai.init(project=self.google_project_id, location=self.google_location)
        model = TextEmbeddingModel.from_pretrained(self.embedding_model_google)
        if self.embedding_model_google == 'textembedding-gecko@001':
            inputs = [TextEmbeddingInput(text) for text in X]
        else:
            inputs = [TextEmbeddingInput(text, self.google_task) for text in X]
        kwargs = {}
        embeddings = []
        batch_size = self.google_batch_size
        for i in range(0, len(inputs), batch_size):
            batch_inputs = inputs[i:i+batch_size]
            batch_embeddings = model.get_embeddings(batch_inputs, **kwargs)
            embeddings.extend(batch_embeddings)
        return np.array([embedding.values for embedding in embeddings])
    
    def _transform_doc2vec(self, X):
        out = [self.doc2vec_model.infer_vector(simple_preprocess(doc)) for doc in X]
        return np.array(out)

    def _transform_st(self, X):
        model_name = self.embedding_model_st
        model_name_split = model_name.split('@')
        assert len(model_name_split) <= 2, 'Too many @ characters in model name'
        if len(model_name_split) == 1:
            model = SentenceTransformer(model_name_split[0])
        else:
            model = SentenceTransformer(model_name_split[0], revision = model_name_split[1])
        return model.encode(X) 
    
    def _transform_openai(self, X):
        if not self.openai_client:
            raise ValueError('Invalid OpenAI client')
        
        ret = self.openai_client.embeddings.create(
            input = X
            , model = self.embedding_model_openai
        )
        ret = np.array([ret.data[n].embedding for n in range(len(ret.data))])
        return ret
