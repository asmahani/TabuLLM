import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sentence_transformers import SentenceTransformer
from gensim.utils import simple_preprocess
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel
import vertexai

class TextColumnTransformer(BaseEstimator, TransformerMixin):
    """
    A transformer for converting one or more text columns to a numeric matrix using various embedding models.

    This class supports the following text embedding models:
    - OpenAI's large language models (LLM) for embedding
    - Sentence-Transformer (ST) embedding LLMs
    - Doc2Vec (via gensim package)
    - Google Vertex AI's embedding LLMs

    Parameters
    ----------
    model_type : str, default='doc2vec'
        The type of embedding model to use. Must be one of 'openai', 'st', 'doc2vec', or 'google'.
    openai_args : dict, optional
        The arguments for accessing OpenAI's embedding models. Should include:
        - 'client': The OpenAI client object.
        - 'model': The specific OpenAI embedding model to use, default is 'text-embedding-3-large'.
    google_args : dict, optional
        The arguments for accessing Google Vertex AI embedding models. Should include:
        - 'project_id': The Google Cloud project ID.
        - 'location': The location of the Google Vertex AI resources.
        - 'model': The specific Google Vertex AI embedding model to use, default is 'text-embedding-004'.
        - 'task': The task type for Google Vertex AI, default is 'SEMANTIC_SIMILARITY'.
        - 'batch_size': The batch size for Google Vertex AI requests, default is 250.
    st_args : dict, optional
        The arguments for accessing Sentence-Transformer embedding models. Should include:
        - 'model': The specific Sentence Transformer model to use, default is 'sentence-transformers/all-MiniLM-L6-v2'.
    doc2vec_args : dict, optional
        The arguments for accessing Doc2Vec models. Should include:
        - 'model': The specific Doc2Vec model to use, must be one of 'PV-DM' or 'PV-DBOW', default is 'PV-DM'.
        - 'epochs': The number of training epochs for the Doc2Vec model, default is 40.
        - 'vector_size': The size of the vectors generated by the Doc2Vec model, default is 50.
    return_cols_prefix : str, default='X_'
        The prefix for the returned embedding columns.
    colsep : str, default=' || '
        The column separator for concatenating multiple text columns, if applicable.

    Raises
    ------
    ValueError
        If an invalid model type or insufficient arguments for the specified model are provided.
    TypeError
        If the input columns are not of string type.

    Attributes
    ----------
    model_type : str
        The type of embedding model being used.
    openai_args : dict
        The arguments for accessing OpenAI's embedding models.
    google_args : dict
        The arguments for accessing Google Vertex AI embedding models.
    st_args : dict
        The arguments for accessing Sentence-Transformer embedding models.
    doc2vec_args : dict
        The arguments for accessing Doc2Vec models.
    return_cols_prefix : str
        The prefix for the returned columns.
    colsep : str
        The column separator for concatenating multiple text columns.
    doc2vec_fit : gensim.models.Doc2Vec
        The fitted Doc2Vec model (only if model_type is 'doc2vec').

    Methods
    -------
    fit(X, y=None)
        Fit the transformer on the data.
    fit_transform(X, y=None)
        Fit the transformer on the data and then transform it.
    transform(X)
        Transform the data (one or more text columns) into embeddings (numeric matrix).

    """
    
    def __init__(
        self
        , model_type = 'doc2vec'
        , openai_args = None
        , google_args = None
        , st_args = None
        , doc2vec_args = None
        , colsep = ' || '
        , return_cols_prefix = 'X_'
    ):
        if model_type not in ('openai', 'st', 'doc2vec', 'google'):
            raise ValueError('Invalid model type')
        self.model_type = model_type
        
        # Initialize attributes for all models
        self.openai_args = openai_args or {}
        self.google_args = google_args or {}
        self.st_args = st_args or {}
        self.doc2vec_args = doc2vec_args or {}
        
        # for a selected model type, args should be provided
        if model_type == 'openai' and not openai_args:
            raise ValueError('OpenAI arguments must be provided for OpenAI model')
        if model_type == 'google' and not google_args:
            raise ValueError('Google arguments must be provided for Google model')
        if model_type == 'st' and not st_args:
            st_args = {}
        if model_type == 'doc2vec' and not doc2vec_args:
            doc2vec_args = {}
        
        # if openai selected, check args and augment with defaults
        if model_type == 'openai':
            if 'model' not in openai_args:
                openai_args['model'] = 'text-embedding-3-large'
            # client must be provided in the args
            if 'client' not in openai_args:
                raise ValueError('OpenAI client must be provided in the OpenAI arguments')
            self.openai_args = openai_args
        
        # if google selected, check args and augment with defaults
        if model_type == 'google':
            if 'model' not in google_args:
                google_args['model'] = 'text-embedding-004'
            if 'task' not in google_args:
                google_args['task'] = 'SEMANTIC_SIMILARITY'
            if 'batch_size' not in google_args:
                google_args['batch_size'] = 250
            if 'project_id' not in google_args:
                raise ValueError('Google project ID must be provided in the Google arguments')
            if 'location' not in google_args:
                raise ValueError('Google location must be provided in the Google arguments')
            self.google_args = google_args
        
        # if st selected, check args and augment with defaults
        if model_type == 'st':
            if 'model' not in st_args:
                st_args['model'] = 'sentence-transformers/all-MiniLM-L6-v2'
            self.st_args = st_args
        
        # if doc2vec selected, check args and augment with defaults
        if model_type == 'doc2vec':
            if 'model' not in doc2vec_args:
                doc2vec_args['model'] = 'PV-DM'
            else:
                if doc2vec_args['model'] not in ('PV-DM', 'PV-DBOW'):
                    raise ValueError('Doc2Vec model must be one of "PV-DM" or "PV-DBOW"')
            if 'epochs' not in doc2vec_args:
                doc2vec_args['epochs'] = 40
            if 'vector_size' not in doc2vec_args:
                doc2vec_args['vector_size'] = 50
            self.doc2vec_args = doc2vec_args
        
        self.colsep = colsep
        self.return_cols_prefix = return_cols_prefix
        self.doc2vec_fit = None
    
    def prep_X(self, X):
        if not (X.dtypes == 'object').all():
            raise TypeError('All columns of X must be of string (object) type')
        
        Xstr = X.fillna('').astype(str).apply(
            lambda row: self.colsep.join([f'{col}: {row[col]}' for col in X.columns])
            , axis=1
        ).tolist()
        return Xstr

    def _fit_doc2vec(self, X, y = None):
        Xstr = self.prep_X(X)
        
        args = self.doc2vec_args
        
        corpus = [TaggedDocument(words = simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(Xstr)]
        alg = 1 if args['model'] == 'PV-DM' else 0
        model = Doc2Vec(
            corpus
            , vector_size = args['vector_size']
            , window=2, min_count=1
            , epochs = args['epochs']
            , dm = alg
        )
        self.doc2vec_fit = model
        return self
    
    def fit(self, X, y = None):
        """
        Fit the transformer on the data.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to fit.
        y : array-like of shape (n_samples,), optional
            The target values (ignored).

        Returns
        -------
        self : object
            Returns the instance itself.
        """
        if self.model_type == 'doc2vec':
            return self._fit_doc2vec(X, y)
        
        return self

    def fit_transform(self, X, y = None):
        """
        Fit the transformer on the data and then transform it.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to fit and transform.
        y : array-like of shape (n_samples,), optional
            The target values (ignored).

        Returns
        -------
        embeddings : numpy.ndarray of shape (n_samples, embedding_dim)
            The transformed embeddings.
        """
        if self.model_type == 'doc2vec':
            self._fit_doc2vec(X, y)
        return self.transform(X)
    
    def transform(self, X):
        """
        Transform the data into embeddings.

        Parameters
        ----------
        X : array-like of shape (n_samples, n_features)
            The input data to transform.

        Returns
        -------
        embeddings : numpy.ndarray of shape (n_samples, embedding_dim)
            The transformed embeddings.
        """
        
        Xstr = self.prep_X(X)
        
        if self.model_type == 'openai':
            arr = self._transform_openai(Xstr)
        elif self.model_type == 'st':
            arr = self._transform_st(Xstr)
        elif self.model_type == 'doc2vec':
            arr = self._transform_doc2vec(Xstr)
        elif self.model_type == 'google':
            arr = self._transform_google(Xstr)
        else:
            raise ValueError('Invalid model type')
        return pd.DataFrame(
            arr
            , columns = [self.return_cols_prefix + str(i) for i in range(arr.shape[1])]
        )

    def _transform_google(self, X):
        args = self.google_args
        vertexai.init(project = args['project_id'], location = args['location'])
        model = TextEmbeddingModel.from_pretrained(args['model'])
        if args['model'] == 'textembedding-gecko@001':
            inputs = [TextEmbeddingInput(text) for text in X]
        else:
            inputs = [TextEmbeddingInput(text, args['task']) for text in X]
        kwargs = {}
        embeddings = []
        batch_size = args['batch_size']
        for i in range(0, len(inputs), batch_size):
            batch_inputs = inputs[i:i+batch_size]
            batch_embeddings = model.get_embeddings(batch_inputs, **kwargs)
            embeddings.extend(batch_embeddings)
        return np.array([embedding.values for embedding in embeddings])
    
    def _transform_doc2vec(self, X):
        out = [self.doc2vec_fit.infer_vector(simple_preprocess(doc)) for doc in X]
        return np.array(out)

    def _transform_st(self, X):
        args = self.st_args
        model_name = args['model']
        model_name_split = model_name.split('@')
        assert len(model_name_split) <= 2, 'Too many @ characters in model name'
        if len(model_name_split) == 1:
            model = SentenceTransformer(model_name_split[0])
        else:
            model = SentenceTransformer(model_name_split[0], revision = model_name_split[1])
        return model.encode(X) 
    
    def _transform_openai(self, X):
        args = self.openai_args
        if not args['client']:
            raise ValueError('Invalid OpenAI client')
        
        ret = args['client'].embeddings.create(
            input = X
            , model = args['model']
        )
        ret = np.array([ret.data[n].embedding for n in range(len(ret.data))])
        return ret
