{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Explaining AI: The `Explain` Module in `TabuLLM`\n",
    "\n",
    "In previous tutorials, we introduced the `embed` and `cluster` modules of `TabuLLM` which allowed us to apply a diverse collection of text embedding algorithms to text columns in our tabular data, and create clusters based on the embedding vectors. The resulting clusters can be included as a categorical feature in a predictive model, but they can also be used to interpret or explain the embeddings.\n",
    "\n",
    "More specifically, text-generating LLMs can be used to provide desriptive labels for the clusters, which are themselves based on the output of an embedding LLM. We can refer to this as, 'AI Explaining AI'. Furthermore, we can apply statistical tests such as Fisher's exact test or ANOVA (?) to determine which clusters have a significantly different distribution of outcome compared to the rest of the population. The combination of these two (labeling the clusters and associating them with outcome) provides a solid explainability path.\n",
    "\n",
    "To support the above, the `explain` module of `TabuLLM` offers three functions:\n",
    "1. `generate_prompt` to assemble the full text of the prompt, which solicits cluster labels from a text-completion LLM.\n",
    "1. `submit_prompt` which is a thin wrapper around various commercial and open-source LLMs.\n",
    "1. `one_vs_test`, a wrapper for testing the mean outcome within each cluster agains the rest.\n",
    "\n",
    "Below, we discuss each using the AKI dataset introduced in a previous tutorial. Before proceeding, let's load the AKI data, use a small LLM to embed the text column, and perform spherical K-means to split the data into 10 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alire\\anaconda3\\envs\\devTEFE\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\alire\\anaconda3\\envs\\devTEFE\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from TabuLLM.embed import TextColumnTransformer\n",
    "from TabuLLM.cluster import SphericalKMeans\n",
    "df = pd.read_csv('../data/raw.csv')\n",
    "embeddings = TextColumnTransformer(\n",
    "    type = 'st'\n",
    "    , embedding_model_st = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ").fit_transform(df.loc[:, ['diagnoses']])\n",
    "n_clusters = 10\n",
    "cluster_labels = SphericalKMeans(n_clusters=n_clusters).fit_predict(embeddings)\n",
    "#assert np.array_equal(np.unique(cluster_labels), np.arange(0, n_clusters + 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Prompt\n",
    "\n",
    "The prompt consiste of two parts. First is the preamble, which provides the data context and the request to the LLM. Second is the data, in which observations are grouped by their cluster labels, and for each observation, the value of the text field that was used to generate the embeddings and then to produce clusters is printed. There are two ways to generate the preamble: 1) provide the phrases to describe the text field and the observation unit, and let the function automatically generate the preamble, 2) directly provide the preamble. Let's make this all more clear by continuing with our running example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a list of 830 pediatric cardiopulmonary bypass surgeries. Text lines represent planned procedures. Pediatric cardiopulmonary bypass surgeries have been grouped into 10 groups, according to their planned procedures. Please suggest group labels that are representative of their members, and also distinct from each other:\n",
      "\n",
      "=====\n",
      "\n",
      "Group 1:\n",
      "\n",
      "155516. Cardiac conduit failure;010501. Discordant VA connections (TGA);091026. Left pulmonary arterial stenosis;070530. Subpulmonary stenosis\n",
      "155516. Cardiac conduit failure;111100. Pacemaker dysfunction / complication necessitating replacement;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type;070501. RV outflow tract obstruction;070901. LV outflow tract obstruction;110610. Acquired complete AV block\n",
      "070501. RV outflow tract obstruction;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "070900. Subaortic stenosis\n",
      "010404. Double inlet LV;010501. Discordant VA connections (TGA);090592. Pulmonary stenosis\n",
      "010404. Double inlet LV;071505. Single VSD\n",
      "090591. Pulmonary regurgitation;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "090591. Pulmonary regurgitation;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "070903. Subaortic stenosis due to fibromuscular shelf;010140. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect without pulmonary stenosis, ventricular septal defect type\n",
      "070903. Subaortic stenosis due to fibromuscular shelf\n",
      "070901. LV outflow tract obstruction;010501. Discordant VA connections (TGA)\n",
      "070900. Subaortic stenosis\n",
      "010118. Double outlet right ventricle with subpulmonary ventricular septal defect, transposition type; 060209. Straddling mitral valve; 094313. Single coronary supplying all of heart; 010122. Functionally univentricular heart\n",
      "155516. Cardiac conduit failure;010104. Double outlet RV\n"
     ]
    }
   ],
   "source": [
    "from TabuLLM.explain import generate_prompt\n",
    "\n",
    "# a helper function to avoid printing the entire prompt\n",
    "def print_first_n_lines(text, n):\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "prompt = generate_prompt(\n",
    "    text_list = list(df['diagnoses'])\n",
    "    , cluster_labels = cluster_labels\n",
    "    , prompt_observations = 'pediatric cardiopulmonary bypass surgeries'\n",
    "    , prompt_texts = 'planned procedures'\n",
    ")\n",
    "print_first_n_lines(prompt, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the prompt preamble, edit it as needed, and regenerate the full prompt by supplying our modified preamble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following is a list of 830 pediatric cardiopulmonary bypass (CPB) surgeries. Text lines represent procedures performed on each patient. \n",
      "These CPB surgeries have been grouped into 10 groups, according to their planned procedures. \n",
      "Please suggest group labels that are representative of their members, and also distinct from each other:\n",
      "\n",
      "\n",
      "=====\n",
      "\n",
      "Group 1:\n",
      "\n",
      "155516. Cardiac conduit failure;010501. Discordant VA connections (TGA);091026. Left pulmonary arterial stenosis;070530. Subpulmonary stenosis\n",
      "155516. Cardiac conduit failure;111100. Pacemaker dysfunction / complication necessitating replacement;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type;070501. RV outflow tract obstruction;070901. LV outflow tract obstruction;110610. Acquired complete AV block\n",
      "070501. RV outflow tract obstruction;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "070900. Subaortic stenosis\n",
      "010404. Double inlet LV;010501. Discordant VA connections (TGA);090592. Pulmonary stenosis\n",
      "010404. Double inlet LV;071505. Single VSD\n",
      "090591. Pulmonary regurgitation;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "090591. Pulmonary regurgitation;010117. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect and pulmonary stenosis, Fallot type\n",
      "070903. Subaortic stenosis due to fibromuscular shelf;010140. Double outlet right ventricle with subaortic or doubly committed ventricular septal defect without pulmonary stenosis, ventricular septal defect type\n",
      "070903. Subaortic stenosis due to fibromuscular shelf\n"
     ]
    }
   ],
   "source": [
    "preamble = '''\n",
    "The following is a list of 830 pediatric cardiopulmonary bypass (CPB) surgeries. Text lines represent procedures performed on each patient. \n",
    "These CPB surgeries have been grouped into 10 groups, according to their planned procedures. \n",
    "Please suggest group labels that are representative of their members, and also distinct from each other:\n",
    "'''\n",
    "prompt2 = generate_prompt(\n",
    "    text_list = list(df['diagnoses'])\n",
    "    , cluster_labels = cluster_labels\n",
    "    , preamble = preamble\n",
    ")\n",
    "print_first_n_lines(prompt2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the Prompt to LLM\n",
    "\n",
    "### Context Window Limits\n",
    "\n",
    "Next, we will submit our prompt to an LLM to generate cluster labels. Before doing so, it's important to make sure the total size of the prompt does not exceed the specifications of our target LLM. Here are the links to model specifications for OpenAI and Google:\n",
    "- Google: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro\n",
    "- OpenAI: https://platform.openai.com/docs/models\n",
    "\n",
    "We see that OpenAI specifies its *context window* in tokens, while Google's *maximum input tokens* is defined in characters. Let's count the number of characters and tokens in our prompt. While the former is straightforward and easy to calculate, the latter's exact value depends on the tokenizer used, though we are more interestes in an approximate estimate and not an exact number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 89697, number of tokens: 25217\n"
     ]
    }
   ],
   "source": [
    "n_characters = len(prompt2)\n",
    "import tiktoken\n",
    "encoder = tiktoken.encoding_for_model('gpt-4-turbo')\n",
    "n_tokens = len(encoder.encode(prompt2))\n",
    "print(f'Number of characters: {n_characters}, number of tokens: {n_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the above numbers against OpenAI's limits, we see that while the maximum context length of 8192 tokens for the `gpt-4` family is insufficient to handle our prompt, the newer-generation of OpenAI models including `gpt-4-turbo` and `gpt-4o` have an adequate context length of 128k tokens. Likewise, upon examining the Gemini text-completion models form Google, we note that *Gemini 1.0 Pro* and newer models are capable of handling our prompt. In particular, we note that the *Gemini 1.5 Pro* model has an impressive *maximum input tokens* parameter of more than 2 million!\n",
    "\n",
    "The broader point is that this prompt - since it includes the entirety of the text data itself - is likely to be lengthy in most applications, but with the rapid advances in LLMs and increase in the length of their context window, larger datasets can be handled. At the same time, it must be noted that modern LLMs which are capable of handling very long prompts are likely to be quite large in size, and thus would exceed the RAM and processing power of most users' local machines.\n",
    "\n",
    "For this reason, we have currently limited the `explain` module of `TabuLLM` to commercial LLMs from OpenAI and Google. A potential feature on our roadmap is to include an option for *two-stage explanation* to circumvent the limits of some LLMs, especially the open-source ones.\n",
    "\n",
    "### Cost Considerations\n",
    "\n",
    "As with submitting embedding tasks to commercial LLMs, here we must also be aware of the costs. The following links contain pricing information from OpenAI and Google for their text-completion models:\n",
    "- Google: https://cloud.google.com/vertex-ai/generative-ai/pricing\n",
    "- OpenAI: https://openai.com/api/pricing/\n",
    "\n",
    "For instance, we see that if we use the *Gemini 1.5 Flash* model from Google, we would incur \\$0.00001875 per 1,000 characters. For the above prompt, this would amount to 89.697 x 0.00001875 or 0.17 cents, which is negligible. The more advanced *Gemini 1.5 Pro* model costs roughly two orders of magnitude more (\\$0.00125 per 1,000 characters), or about 11 cents.\n",
    "\n",
    "Similarly, for OpenAI's *gpt-4o* model, the price is \\$5.0 per 1 million tokens, which amounts to 12 cents. Unsurprisingly, we see that OpenAI and Google models have very competitive prices for their most advanced models.\n",
    "\n",
    "### AI Explaining AI\n",
    "\n",
    "Having discussed the context window limits and cost aspects, let's finally proceed with submitting our prompt and examining the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some suggested group labels, aiming for both representativeness and distinctiveness:\n",
      "\n",
      "**Group 1:  Double Outlet Right Ventricle & Complex Congenital Heart Defects**\n",
      "\n",
      "* **Reasoning:** This group features a high prevalence of Double Outlet Right Ventricle (DORV) variants and other complex congenital heart defects.  It includes various types of DORV, as well as associated issues like pulmonary stenosis, subaortic stenosis, and TGA. \n",
      "\n",
      "**Group 2: Cardiomyopathies & Heart Failure**\n",
      "\n",
      "* **Reasoning:**  This group primarily consists of patients with various cardiomyopathies, including dilated, hypertrophic, and restrictive forms.  There's a clear focus on cardiomyopathy-related heart failure.\n",
      "\n",
      "**Group 3: Valvular Abnormalities & Congenital Heart Disease**\n",
      "\n",
      "* **Reasoning:**  The focus is on valvular problems, both congenital (e.g., bicuspid aortic valve) and acquired (e.g., mitral regurgitation).  There's a significant presence of congenital heart disease like Tetralogy of Fallot and other complex defects.\n",
      "\n",
      "**Group 4: Atrioventricular Septal Defects**\n",
      "\n",
      "* **Reasoning:** This group is entirely focused on Atrioventricular Septal Defects (AVSD) in various forms, including complete, partial, and balanced/unbalanced. \n",
      "\n",
      "**Group 5: Transposition of the Great Arteries**\n",
      "\n",
      "* **Reasoning:** This group is clearly defined by patients with Transposition of the Great Arteries (TGA).  It includes some variations like concordant/discordant connections and associated defects like pulmonary stenosis.\n",
      "\n",
      "**Group 6: Hypoplastic Left Heart Syndrome & Complex Congenital Defects**\n",
      "\n",
      "* **Reasoning:**  This group is heavily weighted towards Hypoplastic Left Heart Syndrome (HLHS) and variations of pulmonary atresia, but also includes other complex congenital heart defects like common arterial trunk.\n",
      "\n",
      "**Group 7: Ventricular Septal Defects**\n",
      "\n",
      "* **Reasoning:**  The vast majority of this group involves different types of Ventricular Septal Defects (VSD). It includes various VSD locations and associated conditions like pulmonary stenosis and PDA.\n",
      "\n",
      "**Group 8: Atrial Septal Defects**\n",
      "\n",
      "* **Reasoning:** This group is solely focused on Atrial Septal Defects (ASD), primarily secundum type, with some sinus venosus ASDs. \n",
      "\n",
      "**Group 9: Tetralogy of Fallot & Pulmonary Atresia Variants**\n",
      "\n",
      "* **Reasoning:**  This group is dominated by Tetralogy of Fallot and its related conditions like pulmonary atresia and VSD. It includes various variants, such as Fallot with pulmonary atresia and absent pulmonary valve syndrome.\n",
      "\n",
      "**Group 10: Pulmonary Vascular Anomalies & Congenital Heart Disease**\n",
      "\n",
      "* **Reasoning:**  The focus is on pulmonary vascular anomalies, including partial anomalous pulmonary venous connections (PAPVC), pulmonary atresia, and pulmonary arterial sling.  It also includes associated conditions like pulmonary hypertension and congenital heart disease. \n",
      "\n",
      "**Important Note:**  These labels are suggestions. The most appropriate labels may depend on the specific needs of your analysis or the intended audience. It may be helpful to consider:\n",
      "\n",
      "* **Purpose of Grouping:** Why are you grouping these procedures? Is it for clinical research, patient management, or another reason?\n",
      "* **Level of Detail:** How specific do you need the labels to be? \n",
      "* **Clarity and Consistency:**  Ensure your labels are easy to understand and consistent across all groups. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from TabuLLM.explain import generate_response\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "google_project_id = os.getenv('VERTEXAI_PROJECT')\n",
    "google_location = os.getenv('VERTEXAI_LOCATION')\n",
    "\n",
    "response = generate_response(\n",
    "    prompt2\n",
    "    , type = \"google\"\n",
    "    , google_project_id = google_project_id\n",
    "    , google_location = google_location\n",
    "    , google_model = 'gemini-1.5-flash-001'\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While validating the medical sensibility of the above labels requires expert opinion, we can see that at least we have obtained a coherent answer from the LLM.\n",
    "\n",
    "We can also write a small utility function to extract the group names from the LLM response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Double Outlet Right Ventricle & Complex Congenital Heart Defects', 'Cardiomyopathies & Heart Failure', 'Valvular Abnormalities & Congenital Heart Disease', 'Atrioventricular Septal Defects', 'Transposition of the Great Arteries', 'Hypoplastic Left Heart Syndrome & Complex Congenital Defects', 'Ventricular Septal Defects', 'Atrial Septal Defects', 'Tetralogy of Fallot & Pulmonary Atresia Variants', 'Pulmonary Vascular Anomalies & Congenital Heart Disease']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_group_names(text):\n",
    "    pattern = re.compile(r\"\\*\\*Group \\d+: (.*?)\\*\\*\")\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = pattern.findall(text)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "cluster_names = extract_group_names(response)\n",
    "print(cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association of Clusters with Outcome\n",
    "\n",
    "Now that we have come up with descriptive labels for the clusters based on the embedding vectors, it will be insightful to see which clusters show a significant difference from the rest of the data in terms of prevalence of outcome. In our case, the outcome is a binary variable that reflects the severity of postoperative acute kidney injury. For such binary classification problems, we can use the Fisher's exact test to compare the odds of severe AKI in each cluster against the remaining clusters. This is done readily using the `one_vs_rest` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TabuLLM.explain import one_vs_rest\n",
    "fisher = one_vs_rest(\n",
    "    pd.DataFrame({\n",
    "        'cluster': cluster_labels\n",
    "        , 'outcome': df['aki_severity']\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the above with the cluster labels into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>Statistic</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Double Outlet Right Ventricle &amp; Complex Conge...</td>\n",
       "      <td>0.568510</td>\n",
       "      <td>1.030710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiomyopathies &amp; Heart Failure</td>\n",
       "      <td>6.468750</td>\n",
       "      <td>2.687169e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valvular Abnormalities &amp; Congenital Heart Disease</td>\n",
       "      <td>1.053571</td>\n",
       "      <td>8.169446e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atrioventricular Septal Defects</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transposition of the Great Arteries</td>\n",
       "      <td>0.371843</td>\n",
       "      <td>1.104734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hypoplastic Left Heart Syndrome &amp; Complex Cong...</td>\n",
       "      <td>1.260627</td>\n",
       "      <td>2.818915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ventricular Septal Defects</td>\n",
       "      <td>1.197822</td>\n",
       "      <td>3.735867e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atrial Septal Defects</td>\n",
       "      <td>0.153629</td>\n",
       "      <td>6.890210e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tetralogy of Fallot &amp; Pulmonary Atresia Variants</td>\n",
       "      <td>1.252945</td>\n",
       "      <td>3.799128e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pulmonary Vascular Anomalies &amp; Congenital Hear...</td>\n",
       "      <td>0.494785</td>\n",
       "      <td>3.383647e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Group Name  Statistic       P-value\n",
       "0   Double Outlet Right Ventricle & Complex Conge...   0.568510  1.030710e-01\n",
       "1                   Cardiomyopathies & Heart Failure   6.468750  2.687169e-08\n",
       "2  Valvular Abnormalities & Congenital Heart Disease   1.053571  8.169446e-01\n",
       "3                    Atrioventricular Septal Defects   1.009901  1.000000e+00\n",
       "4                Transposition of the Great Arteries   0.371843  1.104734e-01\n",
       "5  Hypoplastic Left Heart Syndrome & Complex Cong...   1.260627  2.818915e-01\n",
       "6                         Ventricular Septal Defects   1.197822  3.735867e-01\n",
       "7                              Atrial Septal Defects   0.153629  6.890210e-06\n",
       "8   Tetralogy of Fallot & Pulmonary Atresia Variants   1.252945  3.799128e-01\n",
       "9  Pulmonary Vascular Anomalies & Congenital Hear...   0.494785  3.383647e-02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher['Group Name'] = cluster_names\n",
    "fisher = fisher[['Group Name', 'Statistic', 'P-value']]\n",
    "fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize the explanation, we have concluded that:\n",
    "1. Pediatric CPBs to repair 'Cardiomyopathies and Heart Failure' have ~6.5x odds of being followed by severe AKI.\n",
    "1. On the other hand, operations to repair 'Atrial Septal Defects' have a 6.5x smaller odds of leading to severe AKI, compared to the rest of operations.\n",
    "\n",
    "Setting aside the accuracy and medical plausibility of the above explanations, they facilitate a practitioner's understanding of what embeddings are doing and allows them to decide how much to trust their output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devTEFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
