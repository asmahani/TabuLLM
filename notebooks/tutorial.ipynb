{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TabuLLM`: Feature Extraction from Tabular Data Text using Large Language Models (LLMs) \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Text embedding is the process of converting natural-language text (a single word or an entire document) to a numeric vector. Emeddings can be used as features in predictive models, and it has been shown that modern LLMs can now exceed domain experts in terms of predictive accuracy (Sharabiani et al, 2024). The `TabuLLM` Python package provides various functionalities to support the use of LLMs for feature extraction from text columns of tabular data.\n",
    "\n",
    "In particular, `TabuLLM` consists of four modules:\n",
    "1. `Embed` - Unified interface for converting one or more text column(s) in the data to a numeric matrix, using commercial LLMs (OpenAI, Google Vertex AI), open-source LLMs (available on Hugging Face and accessed via the [sentence transformers](https://sbert.net/) package), as well as earlier-generation embedding methods such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html).\n",
    "1. `Cluster` - Python implementation of [spherical k-means](https://www.jstatsoft.org/article/view/v050i10) for grouping data points according to the embedding vectors produced by LLMs. Since embeddings are L2-normalized, i.e., they only contain directional information and their magnitude is not meaningful, it is more appropriate to use spherical k-means, which replaces the Euclidean distance with [cosine distance](https://en.wikipedia.org/wiki/Cosine_similarity) in standard k-means. (Note: While the cluster-assignment step in the Lloyd's algorithm for esitmating k-means would be identical using Euclidean vs. cosine distance metrics, the centroid-update step would be different since taking a simple average of L2-normalized vectors does not produce another L2-normalized vector.)\n",
    "1. `Explain` - 1) Prompt generation for soliciting descriptive labels for clusters generating based on the embedding vectors, 2) Wrapper for interacting with text-generating LLMs (OpenAI, Google, Hugging Face).\n",
    "1. `Distill` - Applying k-nearest-neighbor - in supervised mode - to predict the outcome using the embedding matrix. Wrapping the KNN in cross-fit allows us to distill the high-dimensional embeddings into a single score, which can subsequently be used alongside other features in the ultimate predictive model.\n",
    "\n",
    "The rest of this tutorial will describe each module in more detail, and illustrate its use via a running example. Before doing so, we provide a brief overview of the dataset that will be used throughout the tutorial.\n",
    "\n",
    "## Dataset: Acute Kidney Injury following Pediatric Cardiopulmonary Bypass\n",
    "\n",
    "(add a description of the AKI dataset)\n",
    "\n",
    "Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_female</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>optime</th>\n",
       "      <th>diagnoses</th>\n",
       "      <th>aki_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18.11</td>\n",
       "      <td>148</td>\n",
       "      <td>80.9</td>\n",
       "      <td>112</td>\n",
       "      <td>155500. Cardiac conduit complication;010125. P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.23</td>\n",
       "      <td>169</td>\n",
       "      <td>56.1</td>\n",
       "      <td>144</td>\n",
       "      <td>091591. Aortic regurgitation;091519. Congenita...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16.86</td>\n",
       "      <td>166</td>\n",
       "      <td>61.6</td>\n",
       "      <td>114</td>\n",
       "      <td>155516. Cardiac conduit failure;090101. Common...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16.88</td>\n",
       "      <td>162</td>\n",
       "      <td>44.3</td>\n",
       "      <td>109</td>\n",
       "      <td>010116. Partial anomalous pulmonary venous con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18.12</td>\n",
       "      <td>175</td>\n",
       "      <td>70.5</td>\n",
       "      <td>119</td>\n",
       "      <td>155516. Cardiac conduit failure;010133. Left h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_female    age  height  weight  optime  \\\n",
       "0          1  18.11     148    80.9     112   \n",
       "1          1  18.23     169    56.1     144   \n",
       "2          1  16.86     166    61.6     114   \n",
       "3          1  16.88     162    44.3     109   \n",
       "4          0  18.12     175    70.5     119   \n",
       "\n",
       "                                           diagnoses  aki_severity  \n",
       "0  155500. Cardiac conduit complication;010125. P...             0  \n",
       "1  091591. Aortic regurgitation;091519. Congenita...             1  \n",
       "2  155516. Cardiac conduit failure;090101. Common...             0  \n",
       "3  010116. Partial anomalous pulmonary venous con...             0  \n",
       "4  155516. Cardiac conduit failure;010133. Left h...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Embed` Module\n",
    "\n",
    "The workhorse of this module is the `TextColumnTransformer` class, which implements `scikit-learn`'s transformer interface, namely the `fit`, `transform` and `fit_transform` methods. The most important argument to the class constructor is `type`, which specifies the type of embedding algorithm to be used. As of this writing (August 2024), the available options are `openai`, `google`, `st` (open-source Hugging Face models accessed via the [`sentence-transformers`](https://sbert.net/) package), and `doc2vec` (via [`gensim`](https://radimrehurek.com/gensim/models/doc2vec.html) package). With the exception of `doc2vec`, the remaining models do not train on the data, which means the `fit` function is simply a pass-through for them.\n",
    "\n",
    "Let's briefly look at how each type of model can be used.\n",
    "\n",
    "### OpenAI\n",
    "\n",
    "The `TextColumnTransformer` class constructor expects two arguments specific to OpenAI: `openai_client` and `embedding_model_openai`. The following code shows how to instantiate an OpenAI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that the user has a valid account with OpenAI and obtained an API key, which is saved as the `OPENAI_API_KEY` environment variable in a `.env` file, which is read by `load_dotenv()`. `embedding_model_openai` must be one of the strings listed on [OpenAI's website](https://platform.openai.com/docs/guides/embeddings/embedding-models). The default is the largest and most accurate model, `text-embedding-3-large`. We can now instantiate and use `TextColumnTransformer`. (NOTE: Running the following code would call OpenAI's embedding model and thus incur a small cost.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1536)\n"
     ]
    }
   ],
   "source": [
    "from TabuLLM.embed import TextColumnTransformer\n",
    "obj = TextColumnTransformer(type = 'openai', openai_client = client, embedding_model_openai = 'text-embedding-3-small')\n",
    "X = obj.fit_transform(df.loc[:5, ['diagnoses']])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we must pass only the text column(s) of interest - as a `pandas` dataframe - to the `fit_transform` function. If multiple text columns are provided, they will be concatenated into a single text column, using the value of the argument `colsep` (which defaults to ` || `).\n",
    "\n",
    "`fit_transform` returns a `pandas` dataframe. While the number of rows is the same as the input dataframe, the number of columns is determined by the embedding model being called. For instance, the embedding vector returned by `text-embedding-3-small` has a length of 1536, as seen above. On the other hand, embeddings returned by OpenAI's latest model, `text-embedding-3-large` have twice the length, i.e., 3072.\n",
    "\n",
    "Let's examine column names of the returned dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X_0', 'X_1', 'X_2', 'X_3', 'X_4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefix is controlled by the argument `return_cols_prefix` to the class constructor (default is `X`, as seen above).\n",
    "\n",
    "### Google (Vertex AI)\n",
    "\n",
    "To use Google's embedding models, we must have a valid Google Cloud Platform account, including a Vertex AI project id and location. As with OpenAI, these can be loaded as environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 768)\n"
     ]
    }
   ],
   "source": [
    "google_project_id = os.getenv('VERTEXAI_PROJECT')\n",
    "google_location = os.getenv('VERTEXAI_LOCATION')\n",
    "\n",
    "X = TextColumnTransformer(\n",
    "    type = 'google'\n",
    "    , google_project_id = google_project_id\n",
    "    , google_location = google_location\n",
    ").fit_transform(df.loc[:5, ['diagnoses']])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that here the Google embeddings have a length of 768, i.e., half of the output from the OpenAI model tested earlier. As with OpenAI, Google also accepts a model type, which we can specify via `embedding_model_google`. Valid options can be found [here](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api). In addition, users can also provide `google_task`, which specifies what downstream application the embeddings will be used for. Options and their descriptions can be found [here](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api). Default in `TextColumnTransformer` is `SEMANTIC_SIMILARITY`.\n",
    "\n",
    "### Sentence Transformers\n",
    "\n",
    "Besides the commercial embedding models provided by OpenAI and Google, we can also use the open-source LLMs that are checked into the Hugging Face platform. The `sentence-transformers` Python package provides a convenient wrapper to download and use these models locally. In addition to using `type = 'st'`, we must also specify `embedding_model_st`. This can be found by browsing to the model's homepage on Hugging Face. Below is an example call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alire\\anaconda3\\envs\\devTEFE\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 384)\n"
     ]
    }
   ],
   "source": [
    "X = TextColumnTransformer(\n",
    "    type = 'st'\n",
    "    , embedding_model_st = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ").fit_transform(df.loc[:5, ['diagnoses']])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that, unlike the case with OpenAI and Google where inference (text embedding, to be more precise) occurs in the cloud, sentence transformer models are downloaded to your machine and run locally. This is especially important when using large models with many parameters, since they require a nontrivial amount of space to store all the weights of their deep neural network, and also performing inference on these networks can be time consuming, unless using accelerators such as GPUs. (The above model, `sentence-transformers/all-MiniLM-L6-v2` was chosen specifically for this example since it is a distilled - very small - model.)\n",
    "\n",
    "An advantage of using sentence transformer models, in addition to being free to use, is that they can be customized for the specific needs of our problem. For instance, we can fine-tune these embedding models on data specific to our application domain. A thorough discussion of fine-tuning is beyond the scope of this tutorial.\n",
    "\n",
    "### Doc2Vec\n",
    "\n",
    "The last type of embedding model included in `TabuLLM` is Doc2Vec (Le and Mikolov, 2014), which is an extension of word2vec. `TextColumnTransformer` uses the implementation of Doc2Vec provided in `gensim`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Sharabiani, Mansour TA, et al. \"Predictive and Explainable Analysis of Post-operative Acute Kidney Injury in Children undergoing Cardiopulmonary Bypass: An Application of Large Language Models.\" medRxiv (2024): 2024-05.\n",
    "1. Le, Quoc, and Tomas Mikolov. \"Distributed representations of sentences and documents.\" International conference on machine learning. PMLR, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devTEFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
